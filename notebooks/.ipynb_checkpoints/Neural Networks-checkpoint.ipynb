{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load libs\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from neural_network import *\n",
    "from image_recognition import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network consists of L total layers: 1 input layer ($x^{(0)}$), $L - 2$ hidden layers ($a^{(1)} ... a^{(l - 1)}$) and 1 output layer ($a^{(L)}$):\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x^{(0)}_{0}\\\\\n",
    "x^{(0)}_{1}\\\\\n",
    "x^{(0)}_{2}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a^{(1)}_{0}\\\\\n",
    "a^{(1)}_{1}\\\\\n",
    "a^{(1)}_{2}\\\\\n",
    "a^{(1)}_{3}\\\\\n",
    "a^{(1)}_{4}\\\\\n",
    "\\end{bmatrix}\n",
    "...\n",
    "\\begin{bmatrix}\n",
    "a^{(l - 1)}_{0}\\\\\n",
    "a^{(l - 1)}_{1}\\\\\n",
    "a^{(l - 1)}_{2}\\\\\n",
    "a^{(l - 1)}_{3}\\\\\n",
    "a^{(l - 1)}_{4}\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a^{(L)}_{0}\\\\\n",
    "a^{(L)}_{1}\\\\\n",
    "a^{(L)}_{2}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Each layer's unit is a logistic regression classifier and connected to the next layer's units with edges of weight $\\theta^{(l)}_{ij}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "\n",
    "Propagating values from left to right to calculate output layer's values.\n",
    "\n",
    "Input layer:\n",
    "\n",
    "$$a^{(0)} = X$$\n",
    "\n",
    "Hidden and output layers:\n",
    "\n",
    "$$a^{(l + 1)} = g((\\Theta^{(l)})^T a^{(l)})$$\n",
    "\n",
    "where $g$ is a logistic regression sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s forward_propagation ../neural_network.py\n",
    "def forward_propagation(layer_coefficients, input_data):\n",
    "    \"\"\"\n",
    "    Calculate neural network output based on input data and layer coefficients.\n",
    "    Forward propagation algorithm.\n",
    "\n",
    "    :param layer_coefficients: 1 x (L - 1) array of layer coefficients vectors, where L - layers count\n",
    "    :param input_data: S0 x m input layer vector, where S0 - input layer units count, m - experiments count\n",
    "    :return: 1 x l vector of layer activation vectors Sl x m, where Sl - l'th layer units count,\n",
    "             m - experiments count\n",
    "    \"\"\"\n",
    "    data = [input_data]  # S0 x m\n",
    "\n",
    "    for theta in layer_coefficients:\n",
    "        data.append(\n",
    "            sigmoid(np.dot(\n",
    "                theta,  # Sl x (S[l-1] + 1)\n",
    "                np.vstack(([np.ones(data[-1].shape[1])], data[-1]))  # (S[l-1] + 1) x m\n",
    "            ))  # Sl x m\n",
    "        )\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load neural network data and weights\n",
    "data = scipy.io.loadmat('../data/ex3data1.mat')\n",
    "x = data['X']  # m x n^2, where m - experiments count, n - square image size\n",
    "y = data['y']  # m x 1 vector of image classes (numbers 0 - 9)\n",
    "\n",
    "weights = scipy.io.loadmat('../data/ex3weights.mat')\n",
    "nn_coefficients = (\n",
    "    weights['Theta1'],  # S1 x (n^2 + 1), where S1 - hidden layer size, n - square image size\n",
    "    weights['Theta2']   # SL x (S1 + 1), where SL - output layer size, S1 - hidden layer size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# find index of the output unit with the max value\n",
    "def predict_digit(nn_coefficients, image):\n",
    "    output_data = forward_propagation(nn_coefficients, image)[-1]\n",
    "    max_index = np.argmax(output_data) + 1\n",
    "    \n",
    "    # data set contains 10 instead of 0\n",
    "    return max_index if max_index < 10 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting digits using already pre-trained neural network $\\Theta$ weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy = 97.52%\n"
     ]
    }
   ],
   "source": [
    "# predict images\n",
    "nn_predictions = [predict_digit(nn_coefficients, image.reshape(image.size, 1)) for image in x]\n",
    "print_predictions_accuracy(nn_predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6, 5, 2, 9, 5, 7, 2, 4, 0, 8, 3, 5, 8, 1, 9, 2, 4, 6, 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_random_images(nn_predictions, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that $L$ - number of layers, $s_l$ - number of units in layer $l$:\n",
    "\n",
    "$$J(\\Theta) = - \\frac{1}{m} \\sum_{i=0}^{m} \\sum_{k=0}^{S_L} \n",
    "        [{ y^{(i)}_k log(h(X^{(i)})_k) + (1 - y^{(i)}_k) log(1 - h(X^{(i)})_k) }] \n",
    "    + \\frac{\\lambda}{2 m} \\sum_{l=0}^{L} \\sum_{i=0}^{s_l} \\sum_{j=1}^{s_i} (\\theta^{(l)}_{ij})^2$$\n",
    "    \n",
    "Calculating cost function as a sum of the last layer's cost functions regularized over all $\\Theta^{(l)}_{ij}$ coefficient values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load -s roll_vector_to_list_of_matrices ../neural_network.py\n",
    "def roll_vector_to_list_of_matrices(v, shapes):\n",
    "    first = 0\n",
    "    result = []\n",
    "\n",
    "    for shape in shapes:\n",
    "        last = first + shape[0] * shape[1]\n",
    "        result.append(np.array(v[first:last]).reshape(shape[0], shape[1]))\n",
    "        first = last\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load -s unroll_list_of_matrices_to_vector ../neural_network.py\n",
    "def unroll_list_of_matrices_to_vector(l):\n",
    "    result_vector = np.array([])\n",
    "    original_shape = []\n",
    "\n",
    "    for m in l:\n",
    "        original_shape.append(m.shape)\n",
    "        result_vector = np.hstack([\n",
    "            result_vector,\n",
    "            m.reshape(m.shape[0] * m.shape[1])\n",
    "        ])\n",
    "\n",
    "    return original_shape, result_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s nn_cost_function ../neural_network.py\n",
    "def nn_cost_function(layer_coefficients, x, y):\n",
    "    \"\"\"\n",
    "    Calculate cost function for neural network\n",
    "\n",
    "    :param layer_coefficients: 1 x (L - 1) array of layer coefficients vectors, where L - layers count\n",
    "    :param x: S0 x m input layer vector, where S0 - input layer units count, m - experiments count\n",
    "    :param y: SL x m expected results matrix, where Sl - output layer units count, m - experiments count\n",
    "    :return: summary cost\n",
    "    \"\"\"\n",
    "    return - 1 / y.shape[1] * np.sum((\n",
    "            np.multiply(y, np.log(forward_propagation(layer_coefficients, x)[-1]))  # SL x m\n",
    "            +\n",
    "            np.multiply((1 - y), np.log(1 - forward_propagation(layer_coefficients, x)[-1]))  # SL x m\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.287629165161319"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check cost function value for provided neural network coefficients\n",
    "def digit_to_output_vector(digit):\n",
    "    \"\"\"\n",
    "    Returns 10 x 1 vector with all 0 except 1 for index corresponding to the provided digit.\n",
    "    If digit == 0, then 10th element == 1.\n",
    "    \"\"\"\n",
    "    out = np.zeros(10)\n",
    "    out[9 if digit == 0 else digit - 1] = 1\n",
    "    return out\n",
    "\n",
    "\n",
    "expected_output = np.array([digit_to_output_vector(d) for d in y]).transpose()\n",
    "nn_cost_function(nn_coefficients, x.transpose(), expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s nn_regularized_cost_function ../neural_network.py\n",
    "def nn_regularized_cost_function(unrolled_layer_coefficients, shape, x, y, regularization_rate):\n",
    "    \"\"\"\n",
    "    Regularized neural network cost function.\n",
    "    See nn_cost_function description.\n",
    "    \"\"\"\n",
    "    layer_coefficients = roll_vector_to_list_of_matrices(unrolled_layer_coefficients, shape)\n",
    "\n",
    "    cost = nn_cost_function(layer_coefficients, x, y)\n",
    "\n",
    "    for theta in layer_coefficients:\n",
    "        unrolled_theta = theta.reshape(theta.shape[0] * theta.shape[1], 1)\n",
    "\n",
    "        cost += regularization_rate / (2 * y.shape[1]) \\\n",
    "                * (unrolled_theta.transpose() @ unrolled_theta)[0, 0]\n",
    "\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38448779624289403"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check regularized cost function value for provided neural network coefficients\n",
    "original_shape, unrolled_nn_coefficients = unroll_list_of_matrices_to_vector(nn_coefficients)\n",
    "\n",
    "nn_regularized_cost_function(unrolled_nn_coefficients, original_shape, x.transpose(), expected_output, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is used to calculate cost function first derivative over all l, i, j:\n",
    "$$\\frac{dJ}{d\\Theta^{(l)}_{ij}}$$\n",
    "\n",
    "Lets introduce cost function error $\\delta^{(l)}$ for each layer $l$ and propagate this value from right to left.\n",
    "\n",
    "For the last layer $L$: \n",
    "$$\\delta^{(L)} = a^{(L)} - y$$\n",
    "\n",
    "For $[2, L-1]$ layers:\n",
    "$$\\delta^{(l)} = (\\Theta^{(l)})^T \\delta^{(l + 1)} \\cdot g^{'}(z^{(l)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s back_propagation ../neural_network.py\n",
    "def back_propagation(layer_coefficients, y, output):\n",
    "    \"\"\"\n",
    "    Calculate error delta values for each layer and unit\n",
    "\n",
    "    :param layer_coefficients: 1 x (L - 1) array of layer coefficients vectors, where L - layers count\n",
    "    :param y: SL x m expected results matrix, where SL - output layer units count, m - experiments count\n",
    "    :param output: 1 x l vector of layer activation vectors Sl x m, where Sl - l'th layer units count,\n",
    "             m - experiments count\n",
    "    :return: 1 x (L - 1) vector of Sl x m delta values\n",
    "    \"\"\"\n",
    "    delta = [output[-1] - y]\n",
    "\n",
    "    for l in reversed(range(1, len(layer_coefficients))):\n",
    "        delta.insert(\n",
    "            0,\n",
    "            np.multiply(\n",
    "                np.dot(\n",
    "                    layer_coefficients[l].transpose(),  # (Sl + 1) x S[l + 1]\n",
    "                    delta[0]  # S[l + 1] x m\n",
    "                )[1:, :],  # Sl x m\n",
    "                sigmoid_derivative(output[l])  # Sl x m\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that: \n",
    "$$a^{(l)} = g(z^{(l)}) = \\frac{1}{1 + e^{-z^{(l)}}}$$\n",
    "\n",
    "$$z^{(l)} = (\\Theta^{(l - 1)})^T a^{(l - 1)}$$\n",
    "\n",
    "And sigmoid function's first derivative: \n",
    "$$g^{'}(z^{(l)}) = g(z^{(l)}) \\cdot (1 - g(z^{(l)})) = a^{(l)} \\cdot (1 - a^{(l)})$$\n",
    "\n",
    "Shows sensitivity of the sigmoid function to the change in input $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s sigmoid_derivative ../neural_network.py\n",
    "def sigmoid_derivative(z):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid function derivative dg/dz\n",
    "    \"\"\"\n",
    "    return np.multiply(z, 1 - z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then:\n",
    "$$\\delta^{(l)} = (\\Theta^{(l)})^T \\delta^{(l + 1)} \\cdot a^{(l)} \\cdot (1 - a^{(l)})$$\n",
    "\n",
    "Each $\\delta^{(l)}$ contributes to the total layer's delta:\n",
    "$$\\Delta^{(l)} := \\Delta^{(l)} + \\delta^{(l + 1)} (a^{(l)})^T$$\n",
    "\n",
    "Then $J(\\Theta)$ first derivative can be calculated as:\n",
    "$$\\frac{dJ}{d\\Theta^{(l)}_{ij}} = \\frac{1}{m} \\Delta^{(l)}_{ij}, j = 0$$\n",
    "$$\\frac{dJ}{d\\Theta^{(l)}_{ij}} = \\frac{1}{m} \\Delta^{(l)}_{ij} \n",
    "    + \\frac{\\lambda}{m}\\Theta^{(l)}_{ij}, j \\gt 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s nn_gradient ../neural_network.py\n",
    "def nn_gradient(layer_coefficients, x, y):\n",
    "    \"\"\"\n",
    "    Neural network gradient (derivative) function\n",
    "\n",
    "    :param layer_coefficients: 1 x (L - 1) array of layer coefficients vectors, where L - layers count\n",
    "    :param x: S0 x m input layer vector, where S0 - input layer units count, m - experiments count\n",
    "    :param y: SL x m expected results matrix, where SL - output layer units count, m - experiments count\n",
    "    :return: 1 x (L - 1) vector of S[l + 1] x (Sl + 1) gradient values\n",
    "    \"\"\"\n",
    "    output = forward_propagation(layer_coefficients, x)  # l, Sl x m\n",
    "    deltas = back_propagation(layer_coefficients, y, output)  # l, Sl x m\n",
    "\n",
    "    grad = []\n",
    "\n",
    "    for l in range(len(deltas)):\n",
    "        grad.append(\n",
    "            1 / y.shape[1] * np.dot(\n",
    "                deltas[l],  # S[l + 1] x m\n",
    "                np.vstack([np.ones(output[l].shape[1]), output[l]]).transpose()  # m x (Sl + 1)\n",
    "            )  # S[l + 1] x (Sl + 1)\n",
    "        )\n",
    "\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s nn_regularized_gradient ../neural_network.py\n",
    "def nn_regularized_gradient(unrolled_layer_coefficients, shape, x, y, regularization_rate):\n",
    "    \"\"\"\n",
    "    Regularized neural network gradient.\n",
    "    See nn_gradient description.\n",
    "    \"\"\"\n",
    "    layer_coefficients = roll_vector_to_list_of_matrices(unrolled_layer_coefficients, shape)\n",
    "\n",
    "    gradients = nn_gradient(layer_coefficients, x, y)\n",
    "\n",
    "    reg_gradients = []\n",
    "\n",
    "    for l in range(len(layer_coefficients) - 1):\n",
    "        reg_gradients.append(\n",
    "            gradients[l]  # S[l + 1] x (Sl + 1)\n",
    "            + regularization_rate / y.shape[1]\n",
    "            * np.hstack([\n",
    "                np.zeros((layer_coefficients[l].shape[0], 1)),\n",
    "                layer_coefficients[l][:, 1:]\n",
    "            ])  # S[l + 1] x (Sl + 1)\n",
    "        )\n",
    "\n",
    "    reg_gradients.append(gradients[-1])\n",
    "\n",
    "    return unroll_list_of_matrices_to_vector(reg_gradients)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.395482\n",
      "         Iterations: 78\n",
      "         Function evaluations: 243\n",
      "         Gradient evaluations: 231\n"
     ]
    }
   ],
   "source": [
    "original_shape = ((25, 401), (10, 26))\n",
    "initial_coefficients = np.random.uniform(-0.12, 0.12, 25*401 + 10*26)\n",
    "\n",
    "coefficients_vector = optimize.fmin_cg(nn_regularized_cost_function,\n",
    "                                       initial_coefficients,\n",
    "                                       fprime=nn_regularized_gradient,\n",
    "                                       args=(original_shape, x.transpose(), expected_output, 1),\n",
    "                                       maxiter=100)\n",
    "\n",
    "nn_learned_coefficients = roll_vector_to_list_of_matrices(coefficients_vector, original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy = 98.26%\n"
     ]
    }
   ],
   "source": [
    "nn_new_predictions = [predict_digit(nn_learned_coefficients, image.reshape(image.size, 1)) for image in x]\n",
    "print_predictions_accuracy(nn_new_predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
