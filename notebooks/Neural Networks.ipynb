{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load libs\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from neural_network import *\n",
    "from image_recognition import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network consists of L total layers: 1 input layer ($x^{(0)}$), $L - 2$ hidden layers ($a^{(1)} ... a^{(l - 1)}$) and 1 output layer ($a^{(L)}$):\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x^{(0)}_{0}\\\\\n",
    "x^{(0)}_{1}\\\\\n",
    "x^{(0)}_{2}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a^{(1)}_{0}\\\\\n",
    "a^{(1)}_{1}\\\\\n",
    "a^{(1)}_{2}\\\\\n",
    "a^{(1)}_{3}\\\\\n",
    "a^{(1)}_{4}\\\\\n",
    "\\end{bmatrix}\n",
    "...\n",
    "\\begin{bmatrix}\n",
    "a^{(l - 1)}_{0}\\\\\n",
    "a^{(l - 1)}_{1}\\\\\n",
    "a^{(l - 1)}_{2}\\\\\n",
    "a^{(l - 1)}_{3}\\\\\n",
    "a^{(l - 1)}_{4}\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a^{(L)}_{0}\\\\\n",
    "a^{(L)}_{1}\\\\\n",
    "a^{(L)}_{2}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Each layer's unit is a logistic regression classifier and connected to the next layer's units with edges of weight $\\theta^{(l)}_{ij}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "\n",
    "Propagating values from left to right to calculate output layer's values.\n",
    "\n",
    "Input layer:\n",
    "\n",
    "$$a^{(0)} = X$$\n",
    "\n",
    "Hidden and output layers:\n",
    "\n",
    "$$a^{(l + 1)} = g((\\Theta^{(l)})^T a^{(l)})$$\n",
    "\n",
    "where $g$ is a logistic regression sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s forward_propagation ../neural_network.py\n",
    "def forward_propagation(layer_coefficients, input_data):\n",
    "    \"\"\"\n",
    "    Calculate neural network output based on input data and layer coefficients.\n",
    "    Forward propagation algorithm.\n",
    "\n",
    "    :param layer_coefficients: 1 x (L - 1) array of layer coefficients vectors, where L - layers count\n",
    "    :param input_data: S0 x m input layer vector, where S0 - input layer units count, m - experiments count\n",
    "    :return: 1 x l vector of layer activation vectors Sl x m, where Sl - l'th layer units count,\n",
    "             m - experiments count\n",
    "    \"\"\"\n",
    "    data = [input_data]  # S0 x m\n",
    "\n",
    "    for theta in layer_coefficients:\n",
    "        data.append(\n",
    "            sigmoid(np.dot(\n",
    "                theta,  # Sl x (S[l-1] + 1)\n",
    "                np.vstack(([np.ones(data[-1].shape[1])], data[-1]))  # (S[l-1] + 1) x m\n",
    "            ))  # Sl x m\n",
    "        )\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load neural network data and weights\n",
    "data = scipy.io.loadmat('../data/ex3data1.mat')\n",
    "x = data['X']  # m x n^2, where m - experiments count, n - square image size\n",
    "y = data['y']  # m x 1 vector of image classes (numbers 0 - 9)\n",
    "\n",
    "weights = scipy.io.loadmat('../data/ex3weights.mat')\n",
    "nn_coefficients = (\n",
    "    weights['Theta1'],  # S1 x (n^2 + 1), where S1 - hidden layer size, n - square image size\n",
    "    weights['Theta2']   # SL x (S1 + 1), where SL - output layer size, S1 - hidden layer size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# find index of the output unit with the max value\n",
    "def predict_digit(nn_coefficients, image):\n",
    "    output_data = forward_propagation(nn_coefficients, image)[-1]\n",
    "    max_index = np.argmax(output_data) + 1\n",
    "    \n",
    "    # data set contains 10 instead of 0\n",
    "    return max_index if max_index < 10 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting digits using already pre-trained neural network $\\Theta$ weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy = 97.52%\n"
     ]
    }
   ],
   "source": [
    "# predict images\n",
    "nn_predictions = [predict_digit(nn_coefficients, image.reshape(image.size, 1)) for image in x]\n",
    "print_predictions_accuracy(nn_predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 5, 2, 7, 6, 4, 2, 8, 0, 8, 0, 9, 1, 7, 0, 1, 1, 3, 4, 6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_random_images(nn_predictions, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that $L$ - number of layers, $s_l$ - number of units in layer $l$:\n",
    "\n",
    "$$J(\\Theta) = - \\frac{1}{m} \\sum_{i=0}^{m} \\sum_{k=0}^{S_L} \n",
    "        [{ y^{(i)}_k log(h(X^{(i)})_k) + (1 - y^{(i)}_k) log(1 - h(X^{(i)})_k) }] \n",
    "    + \\frac{\\lambda}{2 m} \\sum_{l=0}^{L} \\sum_{i=0}^{s_l} \\sum_{j=1}^{s_i} (\\theta^{(l)}_{ij})^2$$\n",
    "    \n",
    "Calculating cost function as a sum of the last layer's cost functions regularized over all $\\Theta^{(l)}_{ij}$ coefficient values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load -s roll_vector_to_list_of_matrices ../neural_network.py\n",
    "def roll_vector_to_list_of_matrices(v, shapes):\n",
    "    first = 0\n",
    "    result = []\n",
    "\n",
    "    for shape in shapes:\n",
    "        last = first + shape[0] * shape[1]\n",
    "        result.append(np.array(v[first:last]).reshape(shape[0], shape[1]))\n",
    "        first = last\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load -s unroll_list_of_matrices_to_vector ../neural_network.py\n",
    "def unroll_list_of_matrices_to_vector(l):\n",
    "    result_vector = np.array([])\n",
    "    original_shape = []\n",
    "\n",
    "    for m in l:\n",
    "        original_shape.append(m.shape)\n",
    "        result_vector = np.hstack([\n",
    "            result_vector,\n",
    "            m.reshape(m.shape[0] * m.shape[1])\n",
    "        ])\n",
    "\n",
    "    return original_shape, result_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s nn_cost_function ../neural_network.py\n",
    "def nn_cost_function(layer_coefficients, x, y):\n",
    "    \"\"\"\n",
    "    Calculate cost function for neural network\n",
    "\n",
    "    :param layer_coefficients: 1 x (L - 1) array of layer coefficients vectors, where L - layers count\n",
    "    :param x: S0 x m input layer vector, where S0 - input layer units count, m - experiments count\n",
    "    :param y: SL x m expected results matrix, where Sl - output layer units count, m - experiments count\n",
    "    :return: summary cost\n",
    "    \"\"\"\n",
    "    return - 1 / y.size * np.sum((\n",
    "            np.multiply(y, np.log(forward_propagation(layer_coefficients, x)[-1]))  # SL x m\n",
    "            +\n",
    "            np.multiply((1 - y), np.log(1 - forward_propagation(layer_coefficients, x)[-1]))  # SL x m\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028762916516131897"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check cost function value for provided neural network coefficients\n",
    "def digit_to_output_vector(digit):\n",
    "    \"\"\"\n",
    "    Returns 10 x 1 vector with all 0 except 1 for index corresponding to the provided digit.\n",
    "    If digit == 0, then 10th element == 1.\n",
    "    \"\"\"\n",
    "    out = np.zeros(10)\n",
    "    out[9 if digit == 0 else digit - 1] = 1\n",
    "    return out\n",
    "\n",
    "\n",
    "expected_output = np.array([digit_to_output_vector(d) for d in y]).transpose()\n",
    "nn_cost_function(nn_coefficients, x.transpose(), expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s nn_regularized_cost_function ../neural_network.py\n",
    "def nn_regularized_cost_function(unrolled_layer_coefficients, shape, x, y, regularization_rate):\n",
    "    \"\"\"\n",
    "    Regularized neural network cost function.\n",
    "    See nn_cost_function description.\n",
    "    \"\"\"\n",
    "    layer_coefficients = roll_vector_to_list_of_matrices(unrolled_layer_coefficients, shape)\n",
    "\n",
    "    cost = nn_cost_function(layer_coefficients, x, y)\n",
    "\n",
    "    for theta in layer_coefficients:\n",
    "        unrolled_theta = theta.reshape(theta.shape[0] * theta.shape[1], 1)\n",
    "\n",
    "        cost += regularization_rate / (2 * y.shape[1]) \\\n",
    "                * (unrolled_theta.transpose() @ unrolled_theta)[0, 0]\n",
    "\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12562154759770694"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check regularized cost function value for provided neural network coefficients\n",
    "original_shape, unrolled_nn_coefficients = unroll_list_of_matrices_to_vector(nn_coefficients)\n",
    "\n",
    "nn_regularized_cost_function(unrolled_nn_coefficients, original_shape, x.transpose(), expected_output, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is used to calculate cost function first derivative over all l, i, j:\n",
    "$$\\frac{dJ}{d\\Theta^{(l)}_{ij}}$$\n",
    "\n",
    "Lets introduce cost function error $\\delta^{(l)}$ for each layer $l$ and propagate this value from right to left.\n",
    "\n",
    "For the last layer $L$: \n",
    "$$\\delta^{(L)} = a^{(L)} - y$$\n",
    "\n",
    "For $[2, L-1]$ layers:\n",
    "$$\\delta^{(l)} = (\\Theta^{(l)})^T \\delta^{(l + 1)} \\cdot g^{'}(z^{(l)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s back_propagation ../neural_network.py\n",
    "def back_propagation(layer_coefficients, y, output):\n",
    "    \"\"\"\n",
    "    Calculate error delta values for each layer and unit\n",
    "\n",
    "    :param layer_coefficients: 1 x (L - 1) array of layer coefficients vectors, where L - layers count\n",
    "    :param y: SL x m expected results matrix, where SL - output layer units count, m - experiments count\n",
    "    :param output: 1 x l vector of layer activation vectors Sl x m, where Sl - l'th layer units count,\n",
    "             m - experiments count\n",
    "    :return: 1 x (L - 1) vector of Sl x m delta values\n",
    "    \"\"\"\n",
    "    delta = [output[-1] - y]\n",
    "\n",
    "    for l in reversed(range(1, len(layer_coefficients))):\n",
    "        delta.insert(\n",
    "            0,\n",
    "            np.multiply(\n",
    "                np.dot(\n",
    "                    layer_coefficients[l].transpose(),  # (Sl + 1) x S[l + 1]\n",
    "                    delta[0]  # S[l + 1] x m\n",
    "                )[1:, :],  # Sl x m\n",
    "                sigmoid_derivative(output[l])  # Sl x m\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that: \n",
    "$$a^{(l)} = g(z^{(l)}) = \\frac{1}{1 + e^{-z^{(l)}}}$$\n",
    "\n",
    "$$z^{(l)} = (\\Theta^{(l - 1)})^T a^{(l - 1)}$$\n",
    "\n",
    "And sigmoid function's first derivative: \n",
    "$$g^{'}(z^{(l)}) = g(z^{(l)}) \\cdot (1 - g(z^{(l)})) = a^{(l)} \\cdot (1 - a^{(l)})$$\n",
    "\n",
    "Shows sensitivity of the sigmoid function to the change in input $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s sigmoid_derivative ../neural_network.py\n",
    "def sigmoid_derivative(z):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid function derivative dg/dz\n",
    "    \"\"\"\n",
    "    return np.multiply(sigmoid(z), 1 - sigmoid(z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then:\n",
    "$$\\delta^{(l)} = (\\Theta^{(l)})^T \\delta^{(l + 1)} \\cdot a^{(l)} \\cdot (1 - a^{(l)})$$\n",
    "\n",
    "Each $\\delta^{(l)}$ contributes to the total layer's delta:\n",
    "$$\\Delta^{(l)} := \\Delta^{(l)} + \\delta^{(l + 1)} (a^{(l)})^T$$\n",
    "\n",
    "Then $J(\\Theta)$ first derivative can be calculated as:\n",
    "$$\\frac{dJ}{d\\Theta^{(l)}_{ij}} = \\frac{1}{m} \\Delta^{(l)}_{ij}, j = 0$$\n",
    "$$\\frac{dJ}{d\\Theta^{(l)}_{ij}} = \\frac{1}{m} \\Delta^{(l)}_{ij} \n",
    "    + \\frac{\\lambda}{m}\\Theta^{(l)}_{ij}, j \\gt 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s nn_gradient ../neural_network.py\n",
    "def nn_gradient(layer_coefficients, x, y):\n",
    "    \"\"\"\n",
    "    Neural network gradient (derivative) function\n",
    "\n",
    "    :param layer_coefficients: 1 x (L - 1) array of layer coefficients vectors, where L - layers count\n",
    "    :param x: S0 x m input layer vector, where S0 - input layer units count, m - experiments count\n",
    "    :param y: SL x m expected results matrix, where SL - output layer units count, m - experiments count\n",
    "    :return: 1 x (L - 1) vector of S[l + 1] x (Sl + 1) gradient values\n",
    "    \"\"\"\n",
    "    output = forward_propagation(layer_coefficients, x)  # l, Sl x m\n",
    "    deltas = back_propagation(layer_coefficients, y, output)  # l, Sl x m\n",
    "\n",
    "    grad = []\n",
    "\n",
    "    for l in range(len(deltas)):\n",
    "        grad.append(\n",
    "            1 / y.shape[1] * np.dot(\n",
    "                deltas[l],  # S[l + 1] x m\n",
    "                np.vstack([np.ones(output[l].shape[1]), output[l]]).transpose()  # m x (Sl + 1)\n",
    "            )  # S[l + 1] x (Sl + 1)\n",
    "        )\n",
    "\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s nn_regularized_gradient ../neural_network.py\n",
    "def nn_regularized_gradient(unrolled_layer_coefficients, shape, x, y, regularization_rate):\n",
    "    \"\"\"\n",
    "    Regularized neural network gradient.\n",
    "    See nn_gradient description.\n",
    "    \"\"\"\n",
    "    layer_coefficients = roll_vector_to_list_of_matrices(unrolled_layer_coefficients, shape)\n",
    "\n",
    "    gradients = nn_gradient(layer_coefficients, x, y)\n",
    "\n",
    "    reg_gradients = []\n",
    "\n",
    "    for l in range(len(layer_coefficients) - 1):\n",
    "        reg_gradients.append(\n",
    "            gradients[l]  # S[l + 1] x (Sl + 1)\n",
    "            + regularization_rate / y.shape[1]\n",
    "            * np.hstack([\n",
    "                np.zeros((layer_coefficients[l].shape[0], 1)),\n",
    "                layer_coefficients[l][:, 1:]\n",
    "            ])  # S[l + 1] x (Sl + 1)\n",
    "        )\n",
    "\n",
    "    reg_gradients.append(gradients[-1])\n",
    "\n",
    "    return unroll_list_of_matrices_to_vector(reg_gradients)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.267751\n",
      "         Iterations: 12\n",
      "         Function evaluations: 92\n",
      "         Gradient evaluations: 81\n"
     ]
    }
   ],
   "source": [
    "original_shape = ((25, 401), (10, 26))\n",
    "initial_coefficients = np.random.uniform(-0.12, 0.12, 25*401 + 10*26)\n",
    "\n",
    "coefficients_vector = optimize.fmin_cg(nn_regularized_cost_function,\n",
    "                                       initial_coefficients,\n",
    "                                       fprime=nn_regularized_gradient,\n",
    "                                       args=(original_shape, x.transpose(), expected_output, 1),\n",
    "                                       maxiter=50)\n",
    "\n",
    "nn_learned_coefficients = roll_vector_to_list_of_matrices(coefficients_vector, original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy = 59.86%\n"
     ]
    }
   ],
   "source": [
    "nn_predictions = [predict_digit(nn_learned_coefficients, image.reshape(image.size, 1)) for image in x]\n",
    "print_predictions_accuracy(nn_predictions, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
